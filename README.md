# 基于卷积神经网络的手势数字识别

本项目是一个基于 PyTorch 框架的卷积神经网络（CNN）手势数字识别项目。旨在通过深度学习技术，实现对 0-9 十个数字手势图像的准确分类。

## 项目背景

随着人机交互需求的不断提高，手势识别作为一种自然、直观的交互方式，在智能家居、虚拟现实、医疗康复等领域展现出巨大的应用潜力。本项目旨在通过搭建、训练和评估一个卷积神经网络，掌握深度学习在图像分类任务中的应用，并达到 80% 以上的分类精度。

## 技术栈

*   **深度学习框架**: PyTorch
*   **主要依赖库**:
    *   `torchvision`: 用于数据预处理和加载。
    *   `scikit-learn`: 用于生成混淆矩阵，评估模型性能。
    *   `matplotlib` & `seaborn`: 用于数据可视化，如损失曲线、准确率曲线和混淆矩阵。
    *   `numpy`: 用于数值计算。
    *   `opencv-python`: 用于图像处理。
    *   `kagglehub`: 用于从 Kaggle 下载数据集。

## 项目结构

```
.
├── best_model.pth      # 训练好的最佳模型权重
├── data_info.py        # 数据集信息分析与划分脚本
├── get_data.py         # 从 Kaggle 下载并解压数据集的脚本
├── model.py            # CNN 模型定义
├── pyproject.toml      # 项目配置文件，包含依赖项
├── README.md           # 项目说明文档
├── test.py             # 模型测试脚本
└── train.py            # 模型训练脚本
```

## 使用说明

### 1. 环境配置

本项目使用 `uv` 作为包管理器。你可以通过以下命令安装所有依赖：

```bash
uv pip install -r requirements.txt
```
*注意：你可能需要根据 `pyproject.toml` 文件手动生成 `requirements.txt` 文件，或者直接使用 `uv pip install` 安装 `pyproject.toml` 中列出的依赖。*

### 2. 数据准备

1.  **下载数据**: 运行 `get_data.py` 脚本从 Kaggle 下载手势数字数据集。
    ```bash
    python get_data.py
    ```
2.  **分析与划分数据**: 运行 `data_info.py` 脚本来分析数据集的基本信息，并将其划分为训练集、验证集和测试集。
    ```bash
    python data_info.py
    ```
    该脚本会自动创建 `dataset_split` 文件夹，并按 70%/15%/15% 的比例存放训练、验证和测试数据。

### 3. 模型训练

运行 `train.py` 脚本来训练模型。训练过程中，脚本会实时打印每个 epoch 的损失和准确率，并将验证集上表现最好的模型权重保存为 `best_model.pth`。

```bash
python train.py
```

训练完成后，会显示损失和准确率随 epoch 变化的图表。

### 4. 模型评估

运行 `test.py` 脚本来评估已保存的最佳模型在测试集上的性能。

```bash
python test.py
```

脚本会输出模型在测试集上的总体准确率，并生成一个可视化的混淆矩阵，以帮助分析模型在每个类别上的具体表现。

## 模型简介

本项目采用了一个简单的卷积神经网络（SimpleCNN），其结构如下：

1.  **三个卷积层**:
    *   `conv1`: 16个 3x3 的卷积核
    *   `conv2`: 32个 3x3 的卷积核
    *   `conv3`: 64个 3x3 的卷积核
    每个卷积层后都跟一个 ReLU 激活函数和一个最大池化层（MaxPool2d）。
2.  **两个全连接层**:
    *   `fc1`: 512个神经元，后跟一个 ReLU 激活函数和一个 Dropout 层（防止过拟合）。
    *   `fc2`: 10个神经元（对应 0-9 十个类别），输出最终的分类结果。

## 实验结果

经过训练，模型在测试集上可以达到 **95.33%** 的分类精度，满足实验要求。具体的分类情况可以参考 `test.py` 输出的混淆矩阵。
