# 手势数字识别实验报告
## 引言
### 项目背景
在当今人机交互技术飞速发展的时代，手势识别作为一种高效、自然的交互手段，其重要性日益凸显。它被广泛应用于智能家居、虚拟现实（VR）、增强现实（AR）、车载系统以及医疗康复等多个领域，极大地提升了人与设备交互的便捷性和效率。本项目旨在通过深度学习方法，解决手势数字图像的分类问题，为更复杂的手势交互应用打下基础。

### 实验目标
本项目的主要目标是：

1. 学习并掌握深度学习开发环境的配置，如 PyTorch 框架的安装与使用。
2. 理解卷积神经网络（CNN）的基本原理和算法流程。
3. 基于 PyTorch 框架，搭建一个卷积神经网络模型。
4. 使用公开的手势数字数据集对所建模型进行训练和优化。
5. 使模型在测试集上的分类精度达到 80% 以上，并对实验结果进行分析。
6. 撰写一份完整的实验报告，记录实验过程、结果与结论。
## 实验环境
### 硬件环境
- CPU/GPU: 本项目代码兼容 CPU、NVIDIA GPU (CUDA) 以及 Apple Silicon (MPS)。训练脚本 train.py 会自动检测并选用最合适的可用设备。
### 软件环境
- 操作系统: Windows/Linux/macOS
- 编程语言: Python 3.12
- 主要依赖库:
    - torch: 核心深度学习框架。
    - torchvision: 提供图像预处理和数据集加载功能。
    - scikit-learn: 用于计算和生成混淆矩阵。
    - matplotlib & seaborn: 用于绘制损失曲线、准确率曲线和混淆矩阵。
    - numpy: 提供核心数值计算支持。
    - opencv-python: 用于图像的读取和基本处理。
    - kagglehub: 用于从 Kaggle 平台自动下载数据集。
## 数据集
### 数据集来源
本项目使用的数据集是来自 Kaggle 平台的 Sign Language for Numbers。该数据集包含了 0 到 9 共 10 个数字的手势图像。

### 数据预处理
为了让数据适应模型训练的需求，我们进行了以下预处理步骤：

1. 尺寸统一: 将所有输入图像的尺寸调整为 128x128 像素。
2. 张量转换: 将 PIL 图像对象转换为 PyTorch 的 Tensor 对象，以便在模型中进行计算。
3. 数据标准化: 使用 ImageNet 数据集的均值 [0.485, 0.456, 0.406] 和标准差 [0.229, 0.224, 0.225] 对图像进行标准化，以加速模型收敛。
4. 数据集划分: 通过 data_info.py 脚本，将原始数据集按照 70%（训练集）、15%（验证集）和 15%（测试集）的比例进行划分，确保模型训练、调优和最终评估的数据相互独立。

## 模型设计
### 模型结构
我们设计了一个名为 SimpleCNN 的卷积神经网络，其结构定义在 model.py 文件中。网络包含以下几个核心部分：

- 三个卷积层 + 池化层:
    - 卷积层1: 输入通道为 3，输出通道为 16，卷积核大小为 3x3。
    - 卷积层2: 输入通道为 16，输出通道为 32，卷积核大小为 3x3。
    - 卷积层3: 输入通道为 32，输出通道为 64，卷积核大小为 3x3。 每个卷积层后都连接一个 ReLU 激活函数用于引入非线性，以及一个 2x2 的最大池化层（MaxPool2d）用于降低特征图的空间维度，提取关键特征。
- 两个全连接层:
    - 全连接层1: 将池化后的特征图展平，输入到 512 个神经元的全连接层。该层后同样使用 ReLU 激活函数，并跟一个 Dropout 层（丢弃率为 0.5）以防止过拟合。
    - 全连接层2: 输出层，将 512 个特征映射到 10 个神经元，分别对应 0-9 十个类别。
### 超参数设置
- 学习率 (Learning Rate): 0.001
- 批量大小 (Batch Size): 64
- 训练轮数 (Epochs): 20
- 优化器 (Optimizer): Adam
- 损失函数 (Loss Function): CrossEntropyLoss (交叉熵损失)，适用于多分类任务。
## 实验流程
### 模型训练
训练过程通过 train.py 脚本执行。在每个 epoch 中，程序会：

1. 在训练集上进行前向传播、计算损失、反向传播和参数更新。
2. 在验证集上评估当前模型的性能（损失和准确率）。
3. 比较当前验证集准确率与历史最佳准确率，如果更优，则将当前模型权重保存为 best_model.pth。 整个训练过程中的训练和验证损失/准确率会被记录下来，并在训练结束后绘制成曲线图。
### 模型评估
训练完成后，使用 test.py 脚本加载 best_model.pth，在独立的测试集上评估模型的最终性能。脚本会计算并打印出模型在测试集上的总体分类准确率，并生成一个可视化的混淆矩阵，用于详细分析模型对每个类别的分类效果。

## 实验结果与分析
### 训练过程
（请在此处粘贴由 train.py 生成的损失和准确率曲线图，并进行分析。例如：分析模型是否收敛、是否存在过拟合或欠拟合等现象。）

[请在此处插入训练曲线图]

### 模型性能
模型在测试集上的最终分类精度为 XX.XX%。 （请在此处粘贴由 test.py 生成的混淆矩阵图，并进行分析。例如：分析哪些数字容易被混淆，模型的强项和弱项分别是什么。）

[请在此处插入混淆矩阵图]

### 结论
（请在此处总结整个实验。例如：本项目成功设计并实现了一个卷积神经网络，用于手势数字识别任务。经过训练和评估，模型在测试集上达到了 XX.XX% 的准确率，满足了预设的实验目标。实验证明了 CNN 在图像分类任务中的有效性... 同时可以提出一些可行的改进方向，如数据增强、模型结构优化等。）

## 项目复现指南
1. 克隆/下载项目
2. 配置环境: 建议使用 uv 或 pip 安装 pyproject.toml 中声明的依赖。
准备数据:
3. 运行 python get_data.py 下载原始数据。
4. 运行 python data_info.py 划分数据集。
5. 模型训练: 运行 python train.py。
6. 模型评估: 运行 python test.py。
